{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/matt/anaconda3/envs/ML/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/matt/anaconda3/envs/ML/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/matt/anaconda3/envs/ML/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/matt/anaconda3/envs/ML/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/matt/anaconda3/envs/ML/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/matt/anaconda3/envs/ML/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import keras\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import sys\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_in_data(filename):\n",
    "\n",
    "    filename = str(filename)\n",
    "\n",
    "    infile = open(filename,'rb')\n",
    "    new_dict = pickle.load(infile)\n",
    "    infile.close()\n",
    "    \n",
    "    return new_dict\n",
    "\n",
    "def var_sifting_data_dicts(input_dict_low, min_cut, max_cut):\n",
    "    \n",
    "    #input_dict_low = input_dict['LOW']\n",
    "    \n",
    "    # initial flux, label, wavelength, redshift, and noise for the stars and quasars\n",
    "    init_flux = input_dict_low['FLUX']\n",
    "    init_labels = input_dict_low['CLASS']\n",
    "    init_wave = input_dict_low['WAVE']\n",
    "    init_redshift = input_dict_low['REDSHIFT']\n",
    "    init_noise = input_dict_low['NOISE']\n",
    "    #init_fake_noise = input_dict_low['FAKE_NOISE']\n",
    "    \n",
    "    \n",
    "    # empty lists to store the flux,labels, wavelength, redshift, and noise for the quasars & stars\n",
    "    quasar_labels = []\n",
    "    quasar_flux = []\n",
    "    quasar_wave = []\n",
    "    quasar_redshift = []\n",
    "    quasar_noise = []\n",
    "    #quasar_fake_noise = []\n",
    "    \n",
    "    star_labels = []\n",
    "    star_flux = []\n",
    "    star_wave = []\n",
    "    star_redshift = []\n",
    "    star_noise = []\n",
    "    #star_fake_noise = []\n",
    "\n",
    "    # check if the classifier actually came back as QSO and if so append to empty list\n",
    "    for i in range(len(init_labels)):\n",
    "        if (init_labels[i] == 'QSO')  & (min(init_wave[i]) <= min_cut) & \\\n",
    "        (max(init_wave[i]) >= max_cut):\n",
    "            \n",
    "            quasar_labels.append(init_labels[i])\n",
    "            quasar_flux.append(init_flux[i])\n",
    "            quasar_wave.append(init_wave[i])\n",
    "            quasar_redshift.append(init_redshift[i])\n",
    "            #quasar_noise.append(init_noise[i])\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    # check if the classifier actually came back as star and if so append to empty list\n",
    "    for i in range(len(init_labels)):\n",
    "        if (init_labels[i] == 'STAR') & (min(init_wave[i]) <= min_cut) & \\\n",
    "        (max(init_wave[i]) >= max_cut) & (init_noise[i] <= 2.):\n",
    "            \n",
    "            star_labels.append(init_labels[i])\n",
    "            star_flux.append(init_flux[i])\n",
    "            star_wave.append(init_wave[i])\n",
    "            star_redshift.append(init_redshift[i])\n",
    "            star_noise.append(init_noise[i])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    data_dict = {'STAR_FLUX':star_flux, 'STAR_LABELS': star_labels, 'STAR_WAVE':star_wave, 'STAR_NOISE': star_noise,\\\n",
    "                 'STAR_REDSHIFT':star_redshift, 'QUASAR_FLUX':quasar_flux, 'QUASAR_LABELS':quasar_labels, \\\n",
    "                 'QUASAR_WAVE': quasar_wave, 'QUASAR_NOISE': quasar_noise, 'QUASAR_REDSHIFT': quasar_redshift}\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def low_sifting_data_dicts(input_dict_low, min_cut, max_cut):\n",
    "    \n",
    "    #input_dict_low = input_dict['LOW']\n",
    "    \n",
    "    # initial flux, label, wavelength, redshift, and noise for the stars and quasars\n",
    "    init_flux = input_dict_low['FLUX']\n",
    "    init_labels = input_dict_low['CLASS']\n",
    "    init_wave = input_dict_low['WAVE']\n",
    "    init_redshift = input_dict_low['REDSHIFT']\n",
    "    init_noise = input_dict_low['NOISE']\n",
    "    init_fake_noise = input_dict_low['FAKE_NOISE']\n",
    "    \n",
    "    \n",
    "    # empty lists to store the flux,labels, wavelength, redshift, and noise for the quasars & stars\n",
    "    quasar_labels = []\n",
    "    quasar_flux = []\n",
    "    quasar_wave = []\n",
    "    quasar_redshift = []\n",
    "    quasar_noise = []\n",
    "    quasar_fake_noise = []\n",
    "    \n",
    "    star_labels = []\n",
    "    star_flux = []\n",
    "    star_wave = []\n",
    "    star_redshift = []\n",
    "    star_noise = []\n",
    "    star_fake_noise = []\n",
    "\n",
    "    # check if the classifier actually came back as QSO and if so append to empty list\n",
    "    for i in range(len(init_labels)):\n",
    "        if (init_labels[i] == 'QSO')  & (min(init_wave[i]) <= min_cut) & \\\n",
    "        (max(init_wave[i]) >= max_cut):\n",
    "            \n",
    "            quasar_labels.append(init_labels[i])\n",
    "            quasar_flux.append(init_flux[i])\n",
    "            quasar_wave.append(init_wave[i])\n",
    "            quasar_redshift.append(init_redshift[i])\n",
    "            quasar_noise.append(init_noise[i])\n",
    "            quasar_fake_noise.append(init_fake_noise[i])\n",
    "\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    # check if the classifier actually came back as star and if so append to empty list\n",
    "    for i in range(len(init_labels)):\n",
    "        if (init_labels[i] == 'STAR') & (min(init_wave[i]) <= min_cut) & \\\n",
    "        (max(init_wave[i]) >= max_cut) & (init_fake_noise[i] <= 2.):\n",
    "            \n",
    "            star_labels.append(init_labels[i])\n",
    "            star_flux.append(init_flux[i])\n",
    "            star_wave.append(init_wave[i])\n",
    "            star_redshift.append(init_redshift[i])\n",
    "            star_noise.append(init_noise[i])\n",
    "            star_fake_noise.append(init_fake_noise[i])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    data_dict = {'STAR_FLUX':star_flux, 'STAR_LABELS': star_labels, 'STAR_WAVE':star_wave, 'STAR_NOISE': star_noise,\\\n",
    "                 'STAR_REDSHIFT':star_redshift, 'STAR_FAKE_NOISE': star_fake_noise, 'QUASAR_FLUX':quasar_flux,\\\n",
    "                 'QUASAR_LABELS':quasar_labels, 'QUASAR_WAVE': quasar_wave, 'QUASAR_NOISE': quasar_noise,\\\n",
    "                 'QUASAR_REDSHIFT': quasar_redshift, 'QUASAR_FAKE_NOISE': quasar_fake_noise}\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def high_sifting_data_dicts(input_dict, min_cut, max_cut):\n",
    "    \n",
    "    input_dict_high = input_dict['HIGH']\n",
    "    \n",
    "    # initial flux, label, wavelength, redshift, and noise for the stars and quasars\n",
    "    init_flux = input_dict_high['FLUX']\n",
    "    init_labels = input_dict_high['CLASS']\n",
    "    init_wave = input_dict_high['WAVE']\n",
    "    init_redshift = input_dict_high['REDSHIFT']\n",
    "    init_noise = input_dict_high['NOISE']\n",
    "    \n",
    "    \n",
    "    # empty lists to store the flux,labels, wavelength, redshift, and noise for the quasars & stars\n",
    "    quasar_labels = []\n",
    "    quasar_flux = []\n",
    "    quasar_wave = []\n",
    "    quasar_redshift = []\n",
    "    quasar_noise = []\n",
    "    \n",
    "    star_labels = []\n",
    "    star_flux = []\n",
    "    star_wave = []\n",
    "    star_redshift = []\n",
    "    star_noise = []\n",
    "\n",
    "    # check if the classifier actually came back as QSO and if so append to empty list\n",
    "    for i in range(len(init_labels)):\n",
    "        if (init_labels[i] == 'QSO')  & (min(init_wave[i]) <= min_cut) & \\\n",
    "        (max(init_wave[i]) >= max_cut) & (init_noise[i] >= 12.):\n",
    "            \n",
    "            quasar_labels.append(init_labels[i])\n",
    "            quasar_flux.append(init_flux[i])\n",
    "            quasar_wave.append(init_wave[i])\n",
    "            quasar_redshift.append(init_redshift[i])\n",
    "            quasar_noise.append(init_noise[i])\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    # check if the classifier actually came back as star and if so append to empty list\n",
    "    for i in range(len(init_labels)):\n",
    "        if (init_labels[i] == 'STAR') & (min(init_wave[i]) <= min_cut) & \\\n",
    "        (max(init_wave[i]) >= max_cut) & (init_noise[i] >= 12.):\n",
    "            \n",
    "            star_labels.append(init_labels[i])\n",
    "            star_flux.append(init_flux[i])\n",
    "            star_wave.append(init_wave[i])\n",
    "            star_redshift.append(init_redshift[i])\n",
    "            star_noise.append(init_noise[i])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    data_dict = {'STAR_FLUX':star_flux, 'STAR_LABELS': star_labels, 'STAR_WAVE':star_wave, 'STAR_NOISE': star_noise,\\\n",
    "                 'STAR_REDSHIFT':star_redshift, 'QUASAR_FLUX':quasar_flux, 'QUASAR_LABELS':quasar_labels, \\\n",
    "                 'QUASAR_WAVE': quasar_wave, 'QUASAR_NOISE': quasar_noise, 'QUASAR_REDSHIFT': quasar_redshift}\n",
    "    \n",
    "    return data_dict    \n",
    "    \n",
    "    \n",
    "def balancing_data(data_dict):\n",
    "    \n",
    "    q_flux = data_dict['QUASAR_FLUX']\n",
    "    q_wave = data_dict['QUASAR_WAVE']\n",
    "    q_labels = data_dict['QUASAR_LABELS']\n",
    "    q_noise = data_dict['QUASAR_NOISE']\n",
    "    q_redshift = data_dict['QUASAR_REDSHIFT']\n",
    "    q_fake_noise = data_dict['QUASAR_FAKE_NOISE']\n",
    "    \n",
    "    s_flux = data_dict['STAR_FLUX']\n",
    "    s_wave = data_dict['STAR_WAVE']\n",
    "    s_labels = data_dict['STAR_LABELS']\n",
    "    s_noise = data_dict['STAR_NOISE']\n",
    "    s_redshift = data_dict['STAR_REDSHIFT']\n",
    "    s_fake_noise = data_dict['STAR_FAKE_NOISE']\n",
    "    \n",
    "    if (len(s_labels)) > (len(q_labels)):\n",
    "        \n",
    "        cut_s_flux = s_flux[:len(q_labels)]\n",
    "        cut_s_wave = s_wave[:len(q_labels)]\n",
    "        cut_s_labels = s_labels[:len(q_labels)]\n",
    "        cut_s_noise = s_noise[:len(q_labels)]\n",
    "        cut_s_redshift = s_redshift[:len(q_labels)]\n",
    "        cut_s_fake_noise = s_fake_noise[:len(q_labels)]\n",
    "        \n",
    "        cut_q_flux = q_flux\n",
    "        cut_q_wave = q_wave\n",
    "        cut_q_labels = q_labels\n",
    "        cut_q_noise = q_noise\n",
    "        cut_q_redshift = q_redshift\n",
    "        cut_q_fake_noise = q_fake_noise\n",
    "        \n",
    "    elif (len(s_labels)) < (len(q_labels)):\n",
    "        \n",
    "        cut_q_flux = q_flux[:len(s_labels)]\n",
    "        cut_q_wave = q_wave[:len(s_labels)]\n",
    "        cut_q_labels = q_labels[:len(s_labels)]\n",
    "        cut_q_noise = q_noise[:len(s_labels)]\n",
    "        cut_q_redshift = q_redshift[:len(s_labels)]\n",
    "        cut_q_fake_noise = q_fake_noise[:len(s_labels)]\n",
    "        \n",
    "        cut_s_flux = s_flux\n",
    "        cut_s_wave = s_wave\n",
    "        cut_s_labels = s_labels\n",
    "        cut_s_noise = s_noise\n",
    "        cut_s_redshift = s_redshift\n",
    "        cut_s_fake_noise = s_fake_noise\n",
    "        \n",
    "    cut_data_dict = {'STAR_FLUX': cut_s_flux, 'STAR_LABELS': cut_s_labels, 'STAR_WAVE':cut_s_wave,\\\n",
    "                     'STAR_NOISE': cut_s_noise,'STAR_REDSHIFT':cut_s_redshift,'STAR_FAKE_NOISE': cut_s_fake_noise,\\\n",
    "                     'QUASAR_FLUX':cut_q_flux, 'QUASAR_LABELS':cut_q_labels, 'QUASAR_WAVE':cut_q_wave,\\\n",
    "                     'QUASAR_NOISE': cut_q_noise, 'QUASAR_REDSHIFT': cut_q_redshift, 'QUASAR_FAKE_NOISE': cut_q_fake_noise}\n",
    "    \n",
    "    return cut_data_dict\n",
    "        \n",
    "        \n",
    "def randomizing_data(data_dict, cut_len, permutation):\n",
    "    \n",
    "    quasar_flux = data_dict['QUASAR_FLUX'][:cut_len]\n",
    "    quasar_labels = data_dict['QUASAR_LABELS'][:cut_len]\n",
    "    quasar_wave = data_dict['QUASAR_WAVE'][:cut_len]\n",
    "    quasar_noise = data_dict['QUASAR_NOISE'][:cut_len]\n",
    "    quasar_redshift = data_dict['QUASAR_REDSHIFT'][:cut_len]\n",
    "    quasar_fake_noise = data_dict['QUASAR_FAKE_NOISE'][:cut_len]\n",
    "    \n",
    "    star_flux = data_dict['STAR_FLUX'][:cut_len]\n",
    "    star_labels = data_dict['STAR_LABELS'][:cut_len] \n",
    "    star_wave = data_dict['STAR_WAVE'][:cut_len]\n",
    "    star_noise = data_dict['STAR_NOISE'][:cut_len]\n",
    "    star_redshift = data_dict['STAR_REDSHIFT'][:cut_len]\n",
    "    star_fake_noise = data_dict['STAR_FAKE_NOISE'][:cut_len]\n",
    "\n",
    "    star_labels = np.ones(len(star_labels))   # STARS = 1\n",
    "    quasar_labels = np.zeros(len(quasar_labels)) # QUASARS = 0\n",
    "    \n",
    "    input_flux = star_flux + quasar_flux\n",
    "    input_flux = np.asarray(input_flux)\n",
    "    \n",
    "    input_labels = np.concatenate((star_labels,quasar_labels), axis = 0)\n",
    "    \n",
    "    input_wave = star_wave + quasar_wave\n",
    "    input_wave = np.asarray(input_wave)\n",
    "    \n",
    "    input_noise = star_noise + quasar_noise\n",
    "    input_noise = np.asarray(input_noise)\n",
    "    \n",
    "    input_redshift = star_redshift+ quasar_redshift\n",
    "    input_redshift = np.asarray(input_redshift)\n",
    "    \n",
    "    input_fake_noise = star_fake_noise + quasar_fake_noise\n",
    "    input_fake_noise = np.asarray(input_fake_noise)\n",
    "    \n",
    "    permutation = np.random.permutation(len(input_flux)) # creates the same permutation to be done on flux & labels\n",
    "    \n",
    "    # needs to be array to permute for classification\n",
    "    randomized_flux = input_flux[permutation] \n",
    "    randomized_labels = input_labels[permutation]\n",
    "    randomized_wave = input_wave[permutation]\n",
    "    randomized_noise = input_noise[permutation]\n",
    "    randomized_redshift = input_redshift[permutation]\n",
    "    randomized_fake_noise = input_fake_noise[permutation]\n",
    "\n",
    "    randomized_flux = randomized_flux.tolist() # needs to be a list to be used in creating tensor function\n",
    "    \n",
    "    randomized_data = {'FLUX': randomized_flux, 'LABELS': randomized_labels, 'WAVE': randomized_wave,\\\n",
    "                      'NOISE': randomized_noise, 'REDSHIFT': randomized_redshift, 'PERMUTATION': permutation,\\\n",
    "                      'FAKE_NOISE': randomized_fake_noise}\n",
    "    \n",
    "    return randomized_data\n",
    "\n",
    "\n",
    "def normalizing_data(data_dict):\n",
    "    \n",
    "    flux = data_dict['FLUX']\n",
    "    labels = data_dict['LABELS']\n",
    "    wave = data_dict['WAVE']\n",
    "    redshift = data_dict['REDSHIFT']\n",
    "    noise = data_dict['NOISE']\n",
    "    fake_noise = data_dict['FAKE_NOISE']\n",
    "    \n",
    "    max_flux = []\n",
    "    normalized_flux = []\n",
    "\n",
    "    for i in range(len(flux)):\n",
    "    \n",
    "        max_flux.append(max(flux[i]))\n",
    "        \n",
    "        edited_flux = flux[i]/max_flux[i]\n",
    "    \n",
    "        normalized_flux.append(edited_flux)\n",
    "        \n",
    "    data = {'FLUX': normalized_flux, 'LABELS': labels, 'WAVE': wave, 'REDSHIFT': redshift, 'NOISE': noise,\\\n",
    "           'FAKE_NOISE': fake_noise}\n",
    "    \n",
    "    return data\n",
    "\n",
    "def creating_image_dims(data_dict):\n",
    "    \n",
    "    flux = data_dict['FLUX']\n",
    "    wave = data_dict['WAVE']\n",
    "    labels = data_dict['LABELS']\n",
    "    redshift = data_dict['REDSHIFT']\n",
    "    noise = data_dict['NOISE']\n",
    "    fake_noise = data_dict['FAKE_NOISE']\n",
    "    cut_spec = []\n",
    "    cut_wave = []\n",
    "    \n",
    "    for i in range(len(flux)): # 3.5817\n",
    "        spec = flux[i]\n",
    "        wavelength = wave[i]\n",
    "        keepidx, = np.where((wave[i] > 3.5818) & (wave[i] < 3.95))\n",
    "        cut_spec.append(spec[keepidx])\n",
    "        cut_wave.append(wavelength[keepidx])\n",
    "    \n",
    "    data = {'FLUX': cut_spec, 'LABELS': labels, 'WAVE': cut_wave, 'REDSHIFT': redshift, 'NOISE': noise,\\\n",
    "           'FAKE_NOISE': fake_noise} #'FLUX': speclen_same\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def creating_input_tensor(samples, height , width , channels , data_dict):\n",
    "    \n",
    "    # creates input tensor of correct dimensions\n",
    "    input_tensor = np.ones((samples, height, width, channels))\n",
    "    \n",
    "    # brings in preprocessed data to input into the dimensions of the tensor\n",
    "    processed_data = creating_image_dims(data_dict)\n",
    "    \n",
    "    # creating the list of the same length fluxs\n",
    "    fluxlen_same = processed_data['FLUX']\n",
    "    \n",
    "    # putting the length of the fluxs lists into the first axis of the tensor, while filling the 3rd axis\n",
    "    # with that specific samples flux array\n",
    "    for i in range(samples):\n",
    "        spec = fluxlen_same[i]\n",
    "        input_tensor[i,0,:,0] = spec[:]\n",
    "        \n",
    "        \n",
    "    data = {'IMAGES': input_tensor, 'LABELS': processed_data['LABELS'], 'NOISE': processed_data['NOISE'],\\\n",
    "           'FLUX': data_dict['FLUX'], 'WAVE': data_dict['WAVE'], 'REDSHIFT': data_dict['REDSHIFT'],\\\n",
    "           'FAKE_NOISE': data_dict['FAKE_NOISE']}\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def save_as_pickled_object(obj, filepath):\n",
    "    \"\"\"\n",
    "    This is a defensive way to write pickle.write, allowing for very large files on all platforms\n",
    "    \"\"\"\n",
    "    max_bytes = 2**31 - 1\n",
    "    bytes_out = pickle.dumps(obj)\n",
    "    n_bytes = sys.getsizeof(bytes_out)\n",
    "    with open(filepath, 'wb') as f_out:\n",
    "        for idx in range(0, n_bytes, max_bytes):\n",
    "            f_out.write(bytes_out[idx:idx+max_bytes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_star_dict = pd.read_pickle(\"/Users/matt/Desktop/DESI_Research/DESI_ML/var_CNN/Dictionaries/joined_obj_dicts/fake_data_dict\")\n",
    "#var_star_dict = pd.read_pickle(\"/Users/matt/Desktop/DESI_Research/DESI_ML/var_CNN/Dictionaries/joined_obj_dicts/varstar_dict\")\n",
    "\n",
    "permutation = pd.read_pickle(\"/Users/matt/Desktop/DESI_Research/DESI_ML/var_CNN/Dictionaries/permutation/var_star_permutation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#var_star_dict['LOW'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_sifted_fake_star_dict = low_sifting_data_dicts(fake_star_dict['LOW'], 3.5818, 3.95)\n",
    "\n",
    "#low_sifted_var_star_dict = var_sifting_data_dicts(var_star_dict['LOW'], 3.5818, 3.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2443\n",
      "2430\n",
      "4910\n"
     ]
    }
   ],
   "source": [
    "print(len(low_sifted_fake_star_dict['STAR_LABELS']))\n",
    "print(len(low_sifted_fake_star_dict['QUASAR_LABELS']))\n",
    "\n",
    "print(len(permutation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_bal_sifted_fake_star_dict = balancing_data(low_sifted_fake_star_dict)\n",
    "\n",
    "#low_bal_sifted_var_star_dict = balancing_data(low_sifted_var_star_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_labels = low_bal_sifted_fake_star_dict['QUASAR_LABELS']\n",
    "s_labels = low_bal_sifted_fake_star_dict['STAR_LABELS']\n",
    "\n",
    "q_noise = low_bal_sifted_fake_star_dict['QUASAR_NOISE']\n",
    "s_noise = low_bal_sifted_fake_star_dict['STAR_NOISE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2430\n",
      "2430\n"
     ]
    }
   ],
   "source": [
    "print(len(q_labels))\n",
    "print(len(s_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4910\n"
     ]
    }
   ],
   "source": [
    "print(len(permutation))\n",
    "# print(permutation_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_randomized_fake_star = randomizing_data(low_bal_sifted_fake_star_dict, 2455, permutation) # \n",
    "\n",
    "#low_randomized_var_star = randomizing_data(low_bal_sifted_var_star_dict, 2455, permutation) # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['FLUX', 'LABELS', 'WAVE', 'NOISE', 'REDSHIFT', 'PERMUTATION', 'FAKE_NOISE'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_randomized_fake_star.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4860"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(low_randomized_fake_star['LABELS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_normalized_fake_star = normalizing_data(low_randomized_fake_star)\n",
    "\n",
    "#low_normalized_var_star = normalizing_data(low_randomized_var_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4860\n"
     ]
    }
   ],
   "source": [
    "print(len(low_normalized_fake_star['LABELS']))\n",
    "#print(len(low_normalized_quasar_star['LABELS']))\n",
    "#print(len(low_normalized_var_star['LABELS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(high_normalized_quasar_star['WAVE'][1], high_normalized_quasar_star['FLUX'][1] )\n",
    "\n",
    "# print(len(low_normalized_fake_star['WAVE'][1]))\n",
    "# print(len(low_normalized_fake_star['FLUX'][1]))\n",
    "# print(low_normalized_fake_star['LABELS'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4466\n",
      "833\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(low_normalized_fake_star['REDSHIFT']))\n",
    "print(np.argmin(low_normalized_fake_star['REDSHIFT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a,b,c = plt.hist(low_normalized_fake_star['LABELS'], bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_fake_star_image_data = creating_image_dims(low_normalized_fake_star)\n",
    "\n",
    "#low_var_star_image_data = creating_image_dims(low_normalized_var_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wave = var_star_image_data['WAVE']\n",
    "# flux = var_star_image_data['FLUX']\n",
    "# label = var_star_image_data['LABELS']\n",
    "# z = var_star_image_data['REDSHIFT']\n",
    "\n",
    "# # 1 is star, 0 is quasar\n",
    "\n",
    "# #plt.plot(wave[17], flux[17], label = \"It is a \"+str(label[17])+\" with a redshift of \"+str(z[17]))\n",
    "# plt.plot(10**wave[7000], flux[7000], label = \"It is a \"+str(label[7000])+\" with a redshift of \"+str(z[7000]))  \n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_fake_star_input_data = creating_input_tensor(4860, 1, 3681 , 1,\\\n",
    "                                   low_fake_star_image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_pickled_object(low_fake_star_input_data, \"/Users/matt/Desktop/DESI_Research/DESI_ML/var_CNN/Dictionaries/corrected_preprocessed_joined_obj_dict/low_fake_star_input_data\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = plt.hist(np.asarray(low_fake_star_input_data['LABELS']), bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(low_fake_star_input_data['IMAGES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(low_fake_star_input_data['WAVE'][4174], low_fake_star_input_data['FLUX'][4174])\n",
    "print(len(low_fake_star_input_data['FLUX'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_star_preprocessed_data_low = pd.read_pickle(\"/Users/matt/Desktop/DESI_Research/DESI_ML/var_CNN/Dictionaries/corrected_preprocessed_joined_obj_dict/var_star_preprocessed_data_low\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_labels = var_star_preprocessed_data_low['LABELS']\n",
    "\n",
    "fake_labels = low_fake_star_input_data['LABELS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(var_star_preprocessed_data_low['WAVE'][0],var_star_preprocessed_data_low['FLUX'][0])\n",
    "plt.plot(low_fake_star_input_data['WAVE'][0], low_fake_star_input_data['FLUX'][0], alpha = 0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(var_labels[4174:4910])\n",
    "print(fake_labels[4174:4910])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save_data_to_disk('quasar_star_preprocessed_data_high', high_quasar_star_input_data)\n",
    "\n",
    "\n",
    "# save_data_to_disk('quasar_star_preprocessed_data_low', low_quasar_star_input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
